{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ffc0dec-cb89-4202-bf1f-0f48d8078493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Table creation for Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c629da1-d654-42e1-839c-5b2fdeec6442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table genai_usecases.multi_step_tools.sensor_readings_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16199865-732e-4636-9a54-461605ffe0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS genai_usecases.multi_step_tools.sensor_readings_delta (\n",
    "  sensor_id STRING,\n",
    "  ts TIMESTAMP,\n",
    "  value DOUBLE\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "-- Insert sensor readings across multiple days\n",
    "INSERT INTO genai_usecases.multi_step_tools.sensor_readings_delta (sensor_id, ts, value) VALUES\n",
    "-- Day 1 readings\n",
    "('sensor_A', TIMESTAMP '2025-10-21 08:00:00', 22.3),\n",
    "('sensor_A', TIMESTAMP '2025-10-21 09:00:00', 23.7),\n",
    "('sensor_A', TIMESTAMP '2025-10-21 10:00:00', 24.0),\n",
    "('sensor_A', TIMESTAMP '2025-10-21 11:00:00', 999.9),  -- anomaly spike\n",
    "('sensor_B', TIMESTAMP '2025-10-21 08:30:00', 49.5),\n",
    "('sensor_B', TIMESTAMP '2025-10-21 09:30:00', 50.2),\n",
    "\n",
    "-- Day 2 readings\n",
    "('sensor_A', TIMESTAMP '2025-10-22 08:00:00', 22.1),\n",
    "('sensor_A', TIMESTAMP '2025-10-22 09:15:00', 23.5),\n",
    "('sensor_A', TIMESTAMP '2025-10-22 10:30:00', -5.0),   -- invalid reading\n",
    "('sensor_B', TIMESTAMP '2025-10-22 08:45:00', 51.0),\n",
    "('sensor_B', TIMESTAMP '2025-10-22 09:45:00', 49.8),\n",
    "('sensor_B', TIMESTAMP '2025-10-22 10:45:00', 52.3),\n",
    "\n",
    "-- Day 3 readings\n",
    "('sensor_A', TIMESTAMP '2025-10-23 08:10:00', 23.0),\n",
    "('sensor_A', TIMESTAMP '2025-10-23 09:10:00', 24.5),\n",
    "('sensor_A', TIMESTAMP '2025-10-23 10:10:00', 25.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-23 08:40:00', 48.7),\n",
    "('sensor_B', TIMESTAMP '2025-10-23 09:40:00', 50.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-23 10:40:00', 5000.0),\n",
    "\n",
    "-- Today readings\n",
    "('sensor_A', TIMESTAMP '2025-10-24 18:10:00', 27.0),\n",
    "('sensor_A', TIMESTAMP '2025-10-24 19:10:00', 24.5),\n",
    "('sensor_A', TIMESTAMP '2025-10-24 12:10:00', 26.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-24 14:40:00', 23.7),\n",
    "('sensor_B', TIMESTAMP '2025-10-24 16:40:00', 98.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-24 20:40:00', 640.0);  -- crazy outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e01cd642-7a8a-4f6c-9dfe-5ed665174e5f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"sensor_id\":126,\"ts\":213,\"value\":134},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761273830428}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sensor_id</th><th>ts</th><th>value</th></tr></thead><tbody><tr><td>sensor_A</td><td>2025-10-21T08:00:00.000Z</td><td>22.3</td></tr><tr><td>sensor_A</td><td>2025-10-21T09:00:00.000Z</td><td>23.7</td></tr><tr><td>sensor_A</td><td>2025-10-21T10:00:00.000Z</td><td>24.0</td></tr><tr><td>sensor_A</td><td>2025-10-21T11:00:00.000Z</td><td>999.9</td></tr><tr><td>sensor_B</td><td>2025-10-21T08:30:00.000Z</td><td>49.5</td></tr><tr><td>sensor_B</td><td>2025-10-21T09:30:00.000Z</td><td>50.2</td></tr><tr><td>sensor_A</td><td>2025-10-22T08:00:00.000Z</td><td>22.1</td></tr><tr><td>sensor_A</td><td>2025-10-22T09:15:00.000Z</td><td>23.5</td></tr><tr><td>sensor_A</td><td>2025-10-22T10:30:00.000Z</td><td>-5.0</td></tr><tr><td>sensor_B</td><td>2025-10-22T08:45:00.000Z</td><td>51.0</td></tr><tr><td>sensor_B</td><td>2025-10-22T09:45:00.000Z</td><td>49.8</td></tr><tr><td>sensor_B</td><td>2025-10-22T10:45:00.000Z</td><td>52.3</td></tr><tr><td>sensor_A</td><td>2025-10-23T08:10:00.000Z</td><td>23.0</td></tr><tr><td>sensor_A</td><td>2025-10-23T09:10:00.000Z</td><td>24.5</td></tr><tr><td>sensor_A</td><td>2025-10-23T10:10:00.000Z</td><td>25.1</td></tr><tr><td>sensor_B</td><td>2025-10-23T08:40:00.000Z</td><td>48.7</td></tr><tr><td>sensor_B</td><td>2025-10-23T09:40:00.000Z</td><td>50.1</td></tr><tr><td>sensor_B</td><td>2025-10-23T10:40:00.000Z</td><td>5000.0</td></tr><tr><td>sensor_A</td><td>2025-10-24T18:10:00.000Z</td><td>27.0</td></tr><tr><td>sensor_A</td><td>2025-10-24T19:10:00.000Z</td><td>24.5</td></tr><tr><td>sensor_A</td><td>2025-10-24T12:10:00.000Z</td><td>26.1</td></tr><tr><td>sensor_B</td><td>2025-10-24T14:40:00.000Z</td><td>23.7</td></tr><tr><td>sensor_B</td><td>2025-10-24T16:40:00.000Z</td><td>98.1</td></tr><tr><td>sensor_B</td><td>2025-10-24T20:40:00.000Z</td><td>640.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "sensor_A",
         "2025-10-21T08:00:00.000Z",
         22.3
        ],
        [
         "sensor_A",
         "2025-10-21T09:00:00.000Z",
         23.7
        ],
        [
         "sensor_A",
         "2025-10-21T10:00:00.000Z",
         24.0
        ],
        [
         "sensor_A",
         "2025-10-21T11:00:00.000Z",
         999.9
        ],
        [
         "sensor_B",
         "2025-10-21T08:30:00.000Z",
         49.5
        ],
        [
         "sensor_B",
         "2025-10-21T09:30:00.000Z",
         50.2
        ],
        [
         "sensor_A",
         "2025-10-22T08:00:00.000Z",
         22.1
        ],
        [
         "sensor_A",
         "2025-10-22T09:15:00.000Z",
         23.5
        ],
        [
         "sensor_A",
         "2025-10-22T10:30:00.000Z",
         -5.0
        ],
        [
         "sensor_B",
         "2025-10-22T08:45:00.000Z",
         51.0
        ],
        [
         "sensor_B",
         "2025-10-22T09:45:00.000Z",
         49.8
        ],
        [
         "sensor_B",
         "2025-10-22T10:45:00.000Z",
         52.3
        ],
        [
         "sensor_A",
         "2025-10-23T08:10:00.000Z",
         23.0
        ],
        [
         "sensor_A",
         "2025-10-23T09:10:00.000Z",
         24.5
        ],
        [
         "sensor_A",
         "2025-10-23T10:10:00.000Z",
         25.1
        ],
        [
         "sensor_B",
         "2025-10-23T08:40:00.000Z",
         48.7
        ],
        [
         "sensor_B",
         "2025-10-23T09:40:00.000Z",
         50.1
        ],
        [
         "sensor_B",
         "2025-10-23T10:40:00.000Z",
         5000.0
        ],
        [
         "sensor_A",
         "2025-10-24T18:10:00.000Z",
         27.0
        ],
        [
         "sensor_A",
         "2025-10-24T19:10:00.000Z",
         24.5
        ],
        [
         "sensor_A",
         "2025-10-24T12:10:00.000Z",
         26.1
        ],
        [
         "sensor_B",
         "2025-10-24T14:40:00.000Z",
         23.7
        ],
        [
         "sensor_B",
         "2025-10-24T16:40:00.000Z",
         98.1
        ],
        [
         "sensor_B",
         "2025-10-24T20:40:00.000Z",
         640.0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "sensor_id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ts",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "value",
            "nullable": true,
            "type": "double"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 28
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sensor_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ts",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from genai_usecases.multi_step_tools.sensor_readings_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c074a914-8da1-4d23-9527-d8f3d8903018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "            SELECT MAX(value) AS max_value \n",
    "            FROM genai_usecases.multi_step_tools.sensor_readings_delta \n",
    "            WHERE sensor_id = 'sensor_B' AND to_date(ts) = to_date('2025-10-23')\n",
    "        \"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e48f1aca-f211-453a-94fa-95a99ed4327a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain databricks-langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd94a0a1-8c4d-4435-8bc4-fd78f2a5817f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "629d18ef-5a31-4461-935f-f4e6d89b316c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5f11135-d860-48dc-9960-5a531cfa779c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"DATABRICKS_HOST\"] = \"{Put your Databricks Hostname here}\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d7cfc18-7eb1-44f0-9ac2-cf7154dcf794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fe1d76-533e-4ab9-be8d-08d5f6b36d07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SensorTools:\n",
    "\n",
    "    @tool\n",
    "    def get_max_sensor_value_for_a_day(sensor_id: str, date: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieves the maximum recorded value for a specific sensor \n",
    "        from the Delta table 'sensor_readings_delta'.\n",
    "        \n",
    "        Args:\n",
    "            sensor_id (str): Name/ID of the sensor.\n",
    "            date (str): Date in 'YYYY-MM-DD' format.\n",
    "        \n",
    "        Returns:\n",
    "            str: The maximum Temperature value as a string.\n",
    "        \"\"\"\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT MAX(value) AS max_value \n",
    "            FROM genai_usecases.multi_step_tools.sensor_readings_delta \n",
    "            WHERE sensor_id = '{sensor_id}' AND to_date(ts) = to_date('{date}')\n",
    "        \"\"\")\n",
    "        \n",
    "        max_val = df.collect()[0][\"max_value\"]\n",
    "        return str(max_val) if max_val is not None else \"No data found\"\n",
    "\n",
    "    @tool\n",
    "    def get_current_date() -> str:\n",
    "        \"\"\"\n",
    "        Returns the current timestamp.\n",
    "\n",
    "        This tool fetches the system's current local date and time. \n",
    "        It is useful for tasks where the LLM needs to reference the actual \n",
    "        current time instead of reasoning about it contextually.\n",
    "\n",
    "        Returns:\n",
    "            str: The current local timestamp in the format YYYY-MM-DD HH:MM:SS.\n",
    "        \"\"\"\n",
    "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    @tool\n",
    "    def get_past_date(days_before: int) -> str:\n",
    "        \"\"\"\n",
    "        Returns the date N days before the current date.\n",
    "\n",
    "        This tool calculates the date that occurred a specific number \n",
    "        of days before today. It is handy for temporal comparisons, \n",
    "        like fetching sensor readings or logs from a few days back.\n",
    "\n",
    "        Args:\n",
    "            days_before (int): Number of days to go back from today.\n",
    "                            Default is 3.\n",
    "\n",
    "        Returns:\n",
    "            str: The date N days before today in the format YYYY-MM-DD.\n",
    "        \"\"\"\n",
    "        past_date = datetime.now() - timedelta(days=days_before)\n",
    "        return past_date.strftime(\"%Y-%m-%d\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a474d67-2993-4923-ba97-9b75eb025b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = [SensorTools.get_max_sensor_value_for_a_day, SensorTools.get_current_date, SensorTools.get_past_date]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7888e8db-b6bc-491d-a682-b2eda37bf052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the question:  What is the max temperature for sensor_B today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finish reason: tool_calls\nCurrent Tool Call details: \n{'name': 'get_current_date', 'args': {}, 'id': 'toolu_bdrk_01CbrmTgg7CwB3cXHXgAXW5s', 'type': 'tool_call'}\nExecuted Tool: get_current_date, Output: 2025-10-24\nModel finish reason: tool_calls\nCurrent Tool Call details: \n{'name': 'get_max_sensor_value_for_a_day', 'args': {'sensor_id': 'sensor_B', 'date': '2025-10-24'}, 'id': 'toolu_bdrk_01BaggsHGQk3vUhcXgToyrH6', 'type': 'tool_call'}\nExecuted Tool: get_max_sensor_value_for_a_day, Output: 640.0\nModel finish reason: stop\n✅ Model completed reasoning — final answer below:\nThe maximum temperature for sensor_B today (2025-10-24) is **640.0**.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the user query\n",
    "# This time, we’re testing multi-step reasoning: the model needs to call multiple tools sequentially.\n",
    "user_query = input(\"Enter the question: \")\n",
    "\n",
    "# Step 2: Create an initial conversation context\n",
    "# It starts with the user's question, wrapped as a HumanMessage.\n",
    "messages = [SystemMessage(\"\"\"You are strictly prohibited from performing any numeric or arithmetic calculations using your own reasoning or internal logic.\n",
    "Do not explain results that come from your own estimation or calculation — rely solely on tool outputs for all numbers.\"\"\"),HumanMessage(user_query)]\n",
    "\n",
    "# Step 3: Run a loop until the model signals that it has finished reasoning\n",
    "# The model keeps responding with tool calls until finish_reason == \"stop\"\n",
    "stop_reason = None\n",
    "\n",
    "while stop_reason != \"stop\":\n",
    "    # Step 4: Invoke the LLM with the current conversation state\n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "\n",
    "    # Capture the reason the model stopped generating text in this iteration\n",
    "    stop_reason = ai_message.response_metadata.get(\"finish_reason\", None)\n",
    "    print(f\"Model finish reason: {stop_reason}\")\n",
    "\n",
    "    # Add the model's message to the conversation history\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    # Step 5: If the model wants to use tools (finish_reason == \"tool_calls\"),\n",
    "    # iterate through them and execute one by one.\n",
    "    if ai_message.tool_calls:\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "\n",
    "            print(\"Current Tool Call details: \")\n",
    "            print(tool_call)\n",
    "            # Step 5a: Match the tool name to the correct Python function.\n",
    "            # Lowercasing ensures we don’t mismatch due to naming conventions.\n",
    "            selected_tool = {\n",
    "                \"get_max_sensor_value_for_a_day\": SensorTools.get_max_sensor_value_for_a_day,\n",
    "                \"get_current_date\": SensorTools.get_current_date,\n",
    "                \"get_past_date\": SensorTools.get_past_date\n",
    "            }[tool_call[\"name\"].lower()]\n",
    "\n",
    "            # Step 5b: Execute the tool and get a ToolMessage back.\n",
    "            # This message structure is automatically handled by LangChain.\n",
    "            tool_msg = selected_tool.invoke(tool_call)\n",
    "\n",
    "            # Step 5c: Append the tool’s response to the conversation.\n",
    "            # This allows the LLM to see its previous reasoning and tool outputs.\n",
    "            messages.append(tool_msg)\n",
    "\n",
    "            print(f\"Executed Tool: {tool_call['name']}, Output: {tool_msg.content}\")\n",
    "\n",
    "    # Step 6: If the model has completed (finish_reason == \"stop\"),\n",
    "    # it means the response is ready — no more tools needed.\n",
    "    elif stop_reason == \"stop\":\n",
    "        print(\"✅ Model completed reasoning — final answer below:\")\n",
    "        print(ai_message.content)\n",
    "        break\n",
    "\n",
    "    # Step 7: Handle unexpected finish reasons (optional but good practice)\n",
    "    else:\n",
    "        print(f\"⚠️ Unexpected finish reason: {stop_reason}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "199ac09f-a052-47c2-8b99-6ce298120ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8578657606195865,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Multi-step Function Calling using Anthropic Claude",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}