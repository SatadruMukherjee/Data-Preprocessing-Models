{
  "metadata": {
    "kernelspec": {
      "name": "jupyter",
      "display_name": "Jupyter Notebook"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "65026b89-ed94-4c7a-a878-f7f7d6aaff82",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_1"
      },
      "source": "%%sql -r dataframe_1\nDROP DATABASE IF EXISTS snowflake_llm_poc;\nCREATE Database snowflake_llm_poc;\nuse snowflake_llm_poc;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e03c8891-9765-4e6b-954a-a5b3751d8359",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_4"
      },
      "source": "%%sql -r dataframe_4\ncreate or replace stage snowflake_llm_poc.PUBLIC.Snow_stage_directory_table_yt url=\"s3://snwoflakeragtest/pdf_knowledge_base/\" \ncredentials=(aws_key_id=''\naws_secret_key='')\nDirectory=(ENABLE=TRUE);",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "51c9436f-0103-4bab-9b38-8cb5eea8c2f9",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_6"
      },
      "source": "%%sql -r dataframe_6\nalter stage snowflake_llm_poc.PUBLIC.Snow_stage_directory_table_yt refresh;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "6dda0887-70e2-486d-af52-0558bf226141",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_5"
      },
      "source": "%%sql -r dataframe_5\nSELECT * FROM directory(@snowflake_llm_poc.PUBLIC.Snow_stage_directory_table_yt);",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "9d582244-4895-4ae4-a90a-71a98dddfed0",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_2"
      },
      "source": "%%sql -r dataframe_2\nCREATE OR REPLACE FUNCTION snowflake_llm_poc.PUBLIC.read_pdf_and_split(file_name STRING)\nRETURNS ARRAY\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.9'\nPACKAGES = ('snowflake-snowpark-python','PyPDF2','langchain')\nHANDLER = 'main_fn'\nAS\n$$\nfrom snowflake.snowpark.files import SnowflakeFile\nimport PyPDF2\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\ndef main_fn(file_name):\n    f = SnowflakeFile.open(file_name, 'rb')\n    pdf_object = PyPDF2.PdfReader(f)\n\n    results = []\n\n    text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=500,\n            chunk_overlap=100,\n            length_function=len\n        )\n\n    # iterate page by page\n    for page_number, page in enumerate(pdf_object.pages, start=1):\n        text = page.extract_text()\n        if not text:\n            continue\n\n        text = text.replace('\\\\n', ' ').replace('\\\\0', ' ')\n        chunks = text_splitter.split_text(text)\n\n        for chunk in chunks:\n            results.append({\n                \"chunk\": chunk,\n                \"page_number\": page_number\n            })\n\n    return results\n$$;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "9567a081-a56e-452a-a9c6-7877c68aebbb",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_7"
      },
      "source": "%%sql -r dataframe_7\nALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'ANY_REGION';",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3c299b72-bee3-4d73-b8dc-53da7700276c",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_8"
      },
      "source": "%%sql -r dataframe_8\n--Storage\ncreate or replace TABLE snowflake_llm_poc.PUBLIC.DOCS_CHUNKS_TABLE ( \n    RELATIVE_PATH VARCHAR(16777216), -- Relative path to the PDF file\n    SIZE NUMBER(38,0), -- Size of the PDF\n    Index Number(38,0), --Index no. of the chunk\n    CHUNK VARCHAR(16777216), -- Piece of text\n    Page_Number Number(38,0), -- Page Number\n    Embedding_Vector VECTOR(FLOAT, 1024)\n);",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "7b5d95b3-86c0-4e9f-8111-30ed7b7ffa04",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_3"
      },
      "source": "%%sql -r dataframe_3\ninsert into snowflake_llm_poc.PUBLIC.docs_chunks_table (relative_path, size, Index,chunk,Page_Number,Embedding_Vector)\nwith splitted_data as (SELECT RELATIVE_PATH,SIZE,read_pdf_and_split(BUILD_SCOPED_FILE_URL( @snowflake_llm_poc.PUBLIC.Snow_stage_directory_table_yt , RELATIVE_PATH )) as pdf_text_split FROM directory(@snowflake_llm_poc.PUBLIC.Snow_stage_directory_table_yt))\nselect Relative_path,SIZE,f.Index,trim(f.value['chunk'],'\"') as chunk,f.value['page_number'] as page_number,\nSNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multilingual-2', trim(f.value['chunk'],'\"')) as Embedding_Vector from splitted_data , lateral flatten(pdf_text_split) f ;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "502faa5d-3992-4af7-81de-b9328eac3926",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_9"
      },
      "source": "%%sql -r dataframe_9\nselect * from snowflake_llm_poc.PUBLIC.docs_chunks_table;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c601e7da-2330-4725-8dcc-33c36c29ee83",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_10"
      },
      "source": "%%sql -r dataframe_10\nSELECT snowflake.cortex.complete(\n    'mistral-large', \n    CONCAT( \n        'Answer the question based on the context. Be concise.','Context: ',\n        (\n            select listagg(chunk,', ') from (SELECT CHUNK from snowflake_llm_poc.PUBLIC.docs_chunks_table\n            ORDER BY VECTOR_L2_DISTANCE(\n            SNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multilingual-2',\n            'How to start Aurora?'\n            ), Embedding_Vector\n            ) limit 3)\n        ),\n        ' Question: ', \n        'How to start Aurora?',\n        'Answer: '\n    )\n) as response;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "a9cb7077-d85b-4847-9411-53984d1ac28b",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom IPython.display import display, Markdown\nsession = get_active_session()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "f7588fd7-80cb-41ea-9ad7-437466e6807e",
      "metadata": {
        "language": "python"
      },
      "source": "#user_question = 'What security features does Amazon Bedrock use to keep my fine-tuning data private and secure?'\nuser_question = 'How can I migrate from MySQL to Aurora?'\nnum_chunks = 5\n\nprint(\"The user question is: \", user_question)\nprint()\n#retrieval\ncmd = f\"\"\"\n        SELECT CHUNK,RELATIVE_PATH,PAGE_Number,VECTOR_COSINE_SIMILARITY(\n        SNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multilingual-2',\n        '{user_question}'\n        ), Embedding_Vector\n        ) as cosine_similarity from snowflake_llm_poc.PUBLIC.docs_chunks_table\n        ORDER BY cosine_similarity desc limit {num_chunks}\n        \"\"\"\n     \ndf_context = session.sql(cmd)\nprint(\"The context is: \")\ndf_context.show()\n\ndf_context = df_context.to_pandas()\n\n\nprompt_context = \"\"\nfor i in range (0, num_chunks):\n    prompt_context += df_context._get_value(i, 'CHUNK').replace(\"'\", \"\")\n\n#augmentation\nprompt = f\"\"\"\n      '''You are an expert assistance extracting information from context provided. \n       Answer the question based on the context. Be concise and do not hallucinate. \n       If you do not have the information just say so.\n      Context: {prompt_context}\n      Question:  \n       {user_question} \n       Answer: '''\n       \"\"\"\n\n#generation\ncmd = f\"\"\"select SNOWFLAKE.CORTEX.COMPLETE('mistral-large',{prompt}) as response\"\"\"\n\ndf_response = session.sql(cmd).collect()\nprint(\"The output of RAG is: \",df_response[0].asDict()['RESPONSE'])\n\n\n#for reference links\ngrouped_df = (\n    df_context.groupby(\"RELATIVE_PATH\")[\"PAGE_NUMBER\"]\n      .apply(lambda x: list(dict.fromkeys(x)))\n      .reset_index(name=\"pages\")\n)\n\ndef generate_presigned_url(pdf_name):\n    query = f\"\"\"\n        SELECT GET_PRESIGNED_URL(\n            @snowflake_llm_poc.PUBLIC.Snow_stage_directory_table_yt,\n            '{pdf_name}',\n            360\n        ) AS presigned_url\n    \"\"\"\n    return session.sql(query).collect()[0][\"PRESIGNED_URL\"]\n\n\ngrouped_df[\"presigned_url\"] = grouped_df[\"RELATIVE_PATH\"].apply(generate_presigned_url)\nprint()\ndef format_sources_from_df(df):\n    lines = [\"### Sources\"]\n    for _, row in df.iterrows():\n        pages = row[\"pages\"]\n        lines.append(\n            f\"- **[{row['RELATIVE_PATH']}]({row['presigned_url']})** â€“ Pages: {pages}\"\n        )\n    return \"\\n\".join(lines)\n\ndisplay(Markdown(format_sources_from_df(grouped_df)))\nprint()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "f06e4cfd-be23-4ec1-ae6d-bdbdf259330e",
      "metadata": {
        "language": "python"
      },
      "source": "",
      "outputs": [],
      "execution_count": null
    }
  ]
}