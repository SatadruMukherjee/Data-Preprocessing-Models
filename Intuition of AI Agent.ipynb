{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58e0489a-48f8-4c0c-a788-9ac48a504272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a53767-a892-4389-bb98-217b37d0df2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "drop table if exists genai_usecases.multi_step_tools.sensor_readings_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82f0b7ba-d79a-4282-a8b0-b031ecd36558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>24</td><td>24</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         24,
         24
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 2
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS genai_usecases.multi_step_tools.sensor_readings_delta (\n",
    "  sensor_id STRING,\n",
    "  ts TIMESTAMP,\n",
    "  value DOUBLE\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "-- Insert sensor readings across multiple days\n",
    "INSERT INTO genai_usecases.multi_step_tools.sensor_readings_delta (sensor_id, ts, value) VALUES\n",
    "-- Day 1 readings\n",
    "('sensor_A', TIMESTAMP '2025-10-21 08:00:00', 22.3),\n",
    "('sensor_A', TIMESTAMP '2025-10-21 09:00:00', 23.7),\n",
    "('sensor_A', TIMESTAMP '2025-10-21 10:00:00', 24.0),\n",
    "('sensor_A', TIMESTAMP '2025-10-21 11:00:00', 999.9),  -- anomaly spike\n",
    "('sensor_B', TIMESTAMP '2025-10-21 08:30:00', 49.5),\n",
    "('sensor_B', TIMESTAMP '2025-10-21 09:30:00', 50.2),\n",
    "\n",
    "-- Day 2 readings\n",
    "('sensor_A', TIMESTAMP '2025-10-22 08:00:00', 22.1),\n",
    "('sensor_A', TIMESTAMP '2025-10-22 09:15:00', 23.5),\n",
    "('sensor_A', TIMESTAMP '2025-10-22 10:30:00', -5.0),   -- invalid reading\n",
    "('sensor_B', TIMESTAMP '2025-10-22 08:45:00', 51.0),\n",
    "('sensor_B', TIMESTAMP '2025-10-22 09:45:00', 49.8),\n",
    "('sensor_B', TIMESTAMP '2025-10-22 10:45:00', 52.3),\n",
    "\n",
    "-- Day 3 readings\n",
    "('sensor_A', TIMESTAMP '2025-10-23 08:10:00', 23.0),\n",
    "('sensor_A', TIMESTAMP '2025-10-23 09:10:00', 24.5),\n",
    "('sensor_A', TIMESTAMP '2025-10-23 10:10:00', 25.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-23 08:40:00', 48.7),\n",
    "('sensor_B', TIMESTAMP '2025-10-23 09:40:00', 50.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-23 10:40:00', 5000.0),\n",
    "\n",
    "-- Today readings\n",
    "('sensor_A', TIMESTAMP '2025-10-24 18:10:00', 27.0),\n",
    "('sensor_A', TIMESTAMP '2025-10-24 19:10:00', 24.5),\n",
    "('sensor_A', TIMESTAMP '2025-10-24 12:10:00', 26.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-24 14:40:00', 23.7),\n",
    "('sensor_B', TIMESTAMP '2025-10-24 16:40:00', 98.1),\n",
    "('sensor_B', TIMESTAMP '2025-10-24 20:40:00', 640.0);  -- crazy outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b760a62-432c-4a21-a3e2-533232a9ed12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Install the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ae0fcd-3235-4d05-8874-96d59f80a58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain databricks-langchain --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6038bc8-29f7-4081-bcb5-799a13bf35bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Perform necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8388af6a-c5a0-4d85-b6bf-b12aecd0aef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8333c8c-d303-40aa-9ee3-8070321cc619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup the required env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eedf67d9-5731-4b70-a417-97346940151c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"DATABRICKS_HOST\"] = \"{Put the Databricks Host Name here}\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19f51d2f-31a6-4a0b-99bd-09d6077c0f79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define the brain of Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20a8a2bb-b90c-4004-a386-25a9f9c7f591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a5b036f-da06-4a2c-8787-ffd2aac4b828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd3fb2a7-f660-406d-b0c8-4ff5b55f16f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SensorTools:\n",
    "\n",
    "    @tool\n",
    "    def get_max_sensor_value_for_a_day(sensor_id: str, date: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieves the maximum recorded value for a specific sensor \n",
    "        from the Delta table 'sensor_readings_delta'.\n",
    "        \n",
    "        Args:\n",
    "            sensor_id (str): Name/ID of the sensor.\n",
    "            date (str): Date in 'YYYY-MM-DD' format.\n",
    "        \n",
    "        Returns:\n",
    "            str: The maximum Temperature value as a string.\n",
    "        \"\"\"\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT MAX(value) AS max_value \n",
    "            FROM genai_usecases.multi_step_tools.sensor_readings_delta  \n",
    "            WHERE sensor_id = '{sensor_id}' AND to_date(ts) = to_date('{date}')\n",
    "        \"\"\")\n",
    "        \n",
    "        max_val = df.collect()[0][\"max_value\"]\n",
    "        return str(max_val) if max_val is not None else \"No data found\"\n",
    "\n",
    "    @tool\n",
    "    def get_current_date() -> str:\n",
    "        \"\"\"\n",
    "        Returns the current timestamp.\n",
    "\n",
    "        This tool fetches the system's current local date and time. \n",
    "        It is useful for tasks where the LLM needs to reference the actual \n",
    "        current time instead of reasoning about it contextually.\n",
    "\n",
    "        Returns:\n",
    "            str: The current local timestamp in the format YYYY-MM-DD HH:MM:SS.\n",
    "        \"\"\"\n",
    "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    @tool\n",
    "    def get_past_date(days_before: int) -> str:\n",
    "        \"\"\"\n",
    "        Returns the date N days before the current date.\n",
    "\n",
    "        This tool calculates the date that occurred a specific number \n",
    "        of days before today. It is handy for temporal comparisons, \n",
    "        like fetching sensor readings or logs from a few days back.\n",
    "\n",
    "        Args:\n",
    "            days_before (int): Number of days to go back from today.\n",
    "                            Default is 3.\n",
    "\n",
    "        Returns:\n",
    "            str: The date N days before today in the format YYYY-MM-DD.\n",
    "        \"\"\"\n",
    "        past_date = datetime.now() - timedelta(days=days_before)\n",
    "        return past_date.strftime(\"%Y-%m-%d\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d413bb-c898-44fd-90ec-ac9f7bc87720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Initialize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef9ba564-b377-4446-a765-0e9bed277b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-05339830-27b8-4b31-832c-0b/.ipykernel/26284/command-7713863096453299-3745285185:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the [LangGraph documentation](https://langchain-ai.github.io/langgraph/) as well as guides for [Migrating from AgentExecutor](https://python.langchain.com/docs/how_to/migrate_agent/) and LangGraph's [Pre-built ReAct agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/).\n  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.agents import AgentType,initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    tools=[SensorTools.get_max_sensor_value_for_a_day, SensorTools.get_current_date, SensorTools.get_past_date],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d578364-e496-45d8-8347-29dcbd43b97b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a91ef5-51d2-4c73-aeb3-f6db419902ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n\u001B[32;1m\u001B[1;3mI need to find the maximum temperature recorded by sensor_B today. First, I need to get today's date, then query the sensor data.\n\nAction:\n```\n{\n  \"action\": \"get_current_date\",\n  \"action_input\": {}\n}\n```\n\n\u001B[0m\nObservation: \u001B[33;1m\u001B[1;3m2025-10-27\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mNow I have today's date (2025-10-27). I can use this to query the maximum temperature for sensor_B.\n\nAction:\n```\n{\n  \"action\": \"get_max_sensor_value_for_a_day\",\n  \"action_input\": {\n    \"sensor_id\": \"sensor_B\",\n    \"date\": \"2025-10-27\"\n  }\n}\n```\n\n\u001B[0m\nObservation: \u001B[36;1m\u001B[1;3mNo data found\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThe query returned no data for sensor_B on today's date (2025-10-27). This could mean that sensor_B hasn't recorded any data today, or there might be no readings available yet.\n\nAction:\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"No temperature data was found for sensor_B today (2025-10-27). This could mean the sensor hasn't recorded any readings yet today, or there may be no data available for this date.\"\n}\n```\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input': 'What is the max temperature recorded by sensor_B today?',\n",
       " 'output': \"No temperature data was found for sensor_B today (2025-10-27). This could mean the sensor hasn't recorded any readings yet today, or there may be no data available for this date.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the max temperature recorded by sensor_B today?\"\n",
    "agent.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c117696-a37a-4f5e-8e4b-56b6a2d2cf4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Check whether it's handling memory or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dbd1841-3993-4779-be34-fe13f57c8f1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n\u001B[32;1m\u001B[1;3mI don't have access to previous conversation history or memory of past questions. Each interaction starts fresh without context from earlier exchanges.\n\nAction:\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"I don't have access to our previous conversation history. Each interaction I have is independent, so I cannot recall what you asked before this current question. If you'd like to discuss something from earlier, please feel free to repeat or rephrase your question, and I'll be happy to help!\"\n}\n```\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input': 'What is the last question I asked?',\n",
       " 'output': \"I don't have access to our previous conversation history. Each interaction I have is independent, so I cannot recall what you asked before this current question. If you'd like to discuss something from earlier, please feel free to repeat or rephrase your question, and I'll be happy to help!\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the last question I asked?\"\n",
    "agent.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df59b157-5b1e-4973-9f79-ab788731c0ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Import the required module for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e9830eb-c842-491c-b9b1-27d6a70e7893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_classic.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c5f73f-4abf-4911-9538-bfb07749ec63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed5552c8-bb11-448b-ad64-9b6c6cf7874a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-05339830-27b8-4b31-832c-0b/.ipykernel/26284/command-4531266607502203-1431103100:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  conversational_memory = ConversationBufferMemory(k=3, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "conversational_memory = ConversationBufferMemory(k=5, return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d22aabd-2d60-418e-a13c-396a93456eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Redefine the agent with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f4ce36-167e-4eae-b18c-d8c8f305224c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_classic.agents import AgentType,initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    tools=[SensorTools.get_max_sensor_value_for_a_day, SensorTools.get_current_date, SensorTools.get_past_date],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=5,\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b392a8-be35-49a7-9c18-ac2c55c78ffe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ask first question to the agent with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac265f3e-4646-4a94-8189-2717403bda05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the User Query:  What is the temperature recorded by sensor_C today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n\u001B[32;1m\u001B[1;3mI need to find the temperature recorded by sensor_C today. First, I need to get today's date, then query the sensor data for that date.\n\nAction:\n```\n{\n  \"action\": \"get_current_date\",\n  \"action_input\": {}\n}\n```\n\n\u001B[0m\nObservation: \u001B[33;1m\u001B[1;3m2025-10-27\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mNow I have today's date (2025-10-27). I need to get the maximum temperature value recorded by sensor_C for this date.\n\nAction:\n```\n{\n  \"action\": \"get_max_sensor_value_for_a_day\",\n  \"action_input\": {\n    \"sensor_id\": \"sensor_C\",\n    \"date\": \"2025-10-27\"\n  }\n}\n```\n\n\u001B[0m\nObservation: \u001B[36;1m\u001B[1;3mNo data found\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThe query returned no data for sensor_C on today's date (2025-10-27). This means either sensor_C hasn't recorded any data today, or there might be no readings available yet for this date.\n\nAction:\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"No temperature data was recorded by sensor_C today (2025-10-27). This could mean the sensor hasn't collected any readings yet today, or there may be no data available for this date.\"\n}\n```\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input': '\\nAnswer the following questions as best you can.\\nChat history: []\\nQuestion: What is the temperature recorded by sensor_C today?',\n",
       " 'history': [HumanMessage(content='\\nAnswer the following questions as best you can.\\nChat history: []\\nQuestion: What is the temperature recorded by sensor_C today?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"No temperature data was recorded by sensor_C today (2025-10-27). This could mean the sensor hasn't collected any readings yet today, or there may be no data available for this date.\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"No temperature data was recorded by sensor_C today (2025-10-27). This could mean the sensor hasn't collected any readings yet today, or there may be no data available for this date.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = input(\"Enter the User Query: \")\n",
    "chat_history = conversational_memory.load_memory_variables({}).get('history','')\n",
    "prompt = f\"\"\"\n",
    "Answer the following questions as best you can.\n",
    "Chat history: {chat_history}\n",
    "Question: {user_query}\"\"\" \n",
    "agent.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fce2a93-58a9-4ac7-9b9a-61bbbd83ad54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ask second question to the agent which is related to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981c2fec-da9e-461e-8218-fb496e1749f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the User Query:  What is the last question I asked?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n\u001B[32;1m\u001B[1;3mI need to look at the chat history to identify the last question the human asked.\n\nLooking at the chat history provided, I can see:\n- The human's last question was: \"What is the temperature recorded by sensor_C today?\"\n- My response indicated that no temperature data was recorded by sensor_C on 2025-10-27.\n\nNow the human is asking what their last question was.\n\nAction:\n```\n{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Your last question was: 'What is the temperature recorded by sensor_C today?'\"\n}\n```\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input': '\\nAnswer the following questions as best you can.\\nChat history: [HumanMessage(content=\\'\\\\nAnswer the following questions as best you can.\\\\nChat history: []\\\\nQuestion: What is the temperature recorded by sensor_C today?\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\"No temperature data was recorded by sensor_C today (2025-10-27). This could mean the sensor hasn\\'t collected any readings yet today, or there may be no data available for this date.\", additional_kwargs={}, response_metadata={})]\\nQuestion: What is the last question I asked?',\n",
       " 'history': [HumanMessage(content='\\nAnswer the following questions as best you can.\\nChat history: []\\nQuestion: What is the temperature recorded by sensor_C today?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"No temperature data was recorded by sensor_C today (2025-10-27). This could mean the sensor hasn't collected any readings yet today, or there may be no data available for this date.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='\\nAnswer the following questions as best you can.\\nChat history: [HumanMessage(content=\\'\\\\nAnswer the following questions as best you can.\\\\nChat history: []\\\\nQuestion: What is the temperature recorded by sensor_C today?\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\"No temperature data was recorded by sensor_C today (2025-10-27). This could mean the sensor hasn\\'t collected any readings yet today, or there may be no data available for this date.\", additional_kwargs={}, response_metadata={})]\\nQuestion: What is the last question I asked?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Your last question was: 'What is the temperature recorded by sensor_C today?'\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"Your last question was: 'What is the temperature recorded by sensor_C today?'\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = input(\"Enter the User Query: \")\n",
    "chat_history = conversational_memory.load_memory_variables({}).get('history','')\n",
    "prompt = f\"\"\"\n",
    "Answer the following questions as best you can.\n",
    "Chat history: {chat_history}\n",
    "Question: {user_query}\"\"\" \n",
    "agent.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7713863096453302,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-10-26 17:32:37",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}