{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "hn5defhncucth6sh53ax",
   "authorId": "1673894472736",
   "authorName": "SATADRU",
   "authorEmail": "satadru1998@gmail.com",
   "sessionId": "0013f597-7163-4a51-bfe9-bf5bfc06ef8f",
   "lastEditTime": 1768132957802
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "5ab14c56-2fb8-4816-8de5-9a9853c39c81",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df2aee3b-e857-4fb3-90b5-a26a88c6a2ed",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\n\n# Get the current active Snowflake session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40bceb1b-ee96-4540-b733-05880d3b3618",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Step 1: Create sample text data\ntexts = [\n    # All related to Machine Learning and AI (38 similar texts)\n    \"Machine learning algorithms learn patterns from training data to make predictions\",\n    \"Supervised learning uses labeled datasets to train predictive models accurately\",\n    \"Neural networks are machine learning models inspired by the human brain structure\",\n    \"Deep learning is a subset of machine learning using multiple neural network layers\",\n    \"Train machine learning models using gradient descent optimization techniques\",\n    \"Machine learning classification predicts categorical output variables from features\",\n    \"Regression models in machine learning predict continuous numerical values\",\n    \"Machine learning requires feature engineering and careful data preprocessing\",\n    \"Overfitting in machine learning occurs when models memorize training data\",\n    \"The best chocolate chip cookie recipe uses brown sugar and vanilla extract for flavor\", #outlier\n    \"Cross-validation technique evaluates machine learning model performance reliably\",\n    \"Natural language processing enables computers to understand human language\",\n    \"Convolutional neural networks excel at image recognition and computer vision tasks\",\n    \"Recurrent neural networks process sequential data like text and time series\",\n    \"Transfer learning reuses pre-trained models for new machine learning tasks\",\n    \"Ensemble methods combine multiple models to improve prediction accuracy\",\n    \"Decision trees split data based on features to make predictions\",\n    \"Random forests use multiple decision trees for robust predictions\",\n    \"Support vector machines find optimal hyperplanes for classification problems\",\n    \"K-means clustering groups similar data points into clusters automatically\",\n    \"Principal component analysis reduces data dimensionality while preserving variance\",\n    \"Reinforcement learning trains agents through rewards and penalties\",\n    \"Backpropagation algorithm trains neural networks by updating weights\",\n        \"The Great Barrier Reef coral ecosystem faces threats from ocean warming and acidification\", #outlier\n    \"Activation functions introduce non-linearity in neural network layers\",\n    \"Batch normalization improves neural network training stability and speed\",\n    \"Dropout technique prevents overfitting by randomly deactivating neurons\",\n    \"Learning rate controls how quickly neural networks update weights\",\n    \"Loss functions measure the difference between predictions and actual values\",\n    \"Hyperparameter tuning optimizes model configuration for better performance\",\n    \"Data augmentation artificially increases training dataset size and variety\",\n    \"Word embeddings represent words as dense vectors in semantic space\",\n    \"Attention mechanisms help neural networks focus on relevant input parts\",\n    \"Transformer architecture revolutionized natural language processing tasks\",\n    \"BERT model uses bidirectional context for language understanding\",\n    \"GPT models generate coherent text using autoregressive language modeling\",\n    \"Fine-tuning adapts pre-trained models to specific downstream tasks\",\n    \"Object detection identifies and localizes objects within images\",\n    \"Semantic segmentation classifies each pixel in an image\",\n    \"Generative adversarial networks create realistic synthetic data samples\"\n]\n\n# Step 2: Create pandas DataFrame\ndf = pd.DataFrame({\n    'id': range(len(texts)),\n    'text': texts\n})\n\nprint(\"Original DataFrame:\")\nprint(df.head())\nprint(f\"\\nTotal texts: {len(df)}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a37c6996-c2a1-433a-be56-b8f767c079fa",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Upload the DataFrame to Snowflake as a temporary table\nsession.create_dataframe(df).write.mode(\"overwrite\").save_as_table(\"TEMP_TEXT_DATA_FOR_ANOMALY_DETECTION\", table_type='temporary')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c66de04-e8cd-4361-88b9-4e66e80b4c32",
   "metadata": {
    "language": "sql",
    "name": "cell20",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT  \"id\",\"text\" FROM TEMP_TEXT_DATA_FOR_ANOMALY_DETECTION ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23d3b8f4-73e8-46bb-b08b-3091e0b850de",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Step 3: Generate embeddings using Snowflake Cortex\nembedding_query = \"\"\"\nSELECT  \"id\", \"text\", SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', \"text\") AS embedding FROM TEMP_TEXT_DATA_FOR_ANOMALY_DETECTION \n\"\"\"\n\n# Execute query and get results as pandas DataFrame\nembed_df = session.sql(embedding_query).to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "603f0536-803b-40a9-ab56-295842c4ff64",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "embed_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "994f6d4e-36a3-4385-a25f-629b1fd5c63b",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "embeddings = np.array([np.array(emb) for emb in embed_df['EMBEDDING']])\n\nprint(f\"\\nEmbeddings shape: {embeddings.shape}\")\nprint(f\"Each text is represented by {embeddings.shape[1]} features (768 dimensions)\")\n\n# Step 5: Normalization (Standardization)\nscaler = StandardScaler()\nembeddings_normalized = scaler.fit_transform(embeddings)\nprint(f\"\\nNormalized embeddings shape: {embeddings_normalized.shape}\")\n\n# Step 6: Apply PCA\nn_components = 2\npca = PCA(n_components=n_components, random_state=42)\nembeddings_pca = pca.fit_transform(embeddings_normalized)\n\nprint(f\"\\nPCA reduced embeddings shape: {embeddings_pca.shape}\")\nprint(f\"Explained variance ratio (first 5 components): {pca.explained_variance_ratio_[:5]}\")\nprint(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.4f}\")\n\n# Step 7: Inverse PCA (Reconstruction)\nembeddings_reconstructed = pca.inverse_transform(embeddings_pca)\nprint(f\"\\nReconstructed embeddings shape: {embeddings_reconstructed.shape}\")\n\n# Step 8: Calculate Reconstruction Error\nreconstruction_error = np.mean((embeddings_normalized - embeddings_reconstructed) ** 2, axis=1)\nprint(f\"\\nReconstruction error shape: {reconstruction_error.shape}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "237c0b5a-9142-4e45-bd67-673ed36a7810",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "embed_df['reconstruction_error'] = reconstruction_error\n\nthreshold = np.percentile(reconstruction_error, 96)\nembed_df['is_anomaly'] = reconstruction_error > threshold",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8bc7fa3c-406e-4e6c-9ecd-d2a9e696a14c",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "embed_df",
   "execution_count": null
  }
 ]
}